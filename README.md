<p align="center">
  <img src="https://raw.githubusercontent.com/ridjan-xhika/V.I.S.A.G.E/main/assets/logo.png" alt="V.I.S.A.G.E Logo" width="200">
</p>

<p align="center">
  <strong>AI-Powered Security Camera System</strong>  
  <br>
  <a href="#features">Features</a> â€¢ 
  <a href="#system-architecture">Architecture</a> â€¢ 
  <a href="#setup">Setup & Installation</a> â€¢ 
  <a href="#usage">Usage</a> â€¢ 
  <a href="#contributing">Contributing</a> â€¢ 
  <a href="#license">License</a>
</p>

---

<p align="center">
  <img src="https://img.shields.io/badge/python-3.8%2B-blue" alt="Python Version">
  <img src="https://img.shields.io/badge/flask-%3E%3D2.0-green" alt="Flask">
  <img src="https://img.shields.io/badge/opencv-%3E%3D4.0-yellow" alt="OpenCV">
  <img src="https://img.shields.io/badge/license-MIT-orange" alt="License">
</p>

---

## ğŸ¯ Project Overview

**V.I.S.A.G.E** (Visual Intelligent Surveillance And Guardian Engine) is an AI-driven security camera platform designed for real-time monitoring, motion detection, face recognition, and instant notifications. Leveraging a lightweight Flask backend, OpenCV detection pipelines, and the Telegram Bot API, V.I.S.A.G.E empowers you to:

* ğŸš€ Stream live video from ESP32-CAM or a standard USB webcam.
* ğŸ•µï¸â€â™‚ï¸ Detect motion with configurable sensitivity and threshold.
* ğŸ§‘â€ğŸ¤â€ğŸ§‘ Identify faces using Haar cascades and store snapshots locally (and optionally in the cloud).
* ğŸ“² Receive instant alerts (with images) via Telegram Bot.
* ğŸ”Œ Control the camera remotely (ON/OFF, snapshots, video clips) through chat commands.
* ğŸ’¾ Log all detections in a local SQLite database, with optional Google Drive backup.

Properly modularized, this system can be extended to other APIs, cloud services, or hardware platforms.

---

## ğŸ”¥ Key Features

| Category             | Details                                                                                  |
| -------------------- | ---------------------------------------------------------------------------------------- |
| **Video Streaming**  | ESP32-CAM or USB webcam â†’ Flask application â†’ MJPEG stream (HTTP endpoint)               |
| **Motion Detection** | OpenCV MOG2 â†’ fast, scalable background subtraction â†’ customizable sensitivity/threshold |
| **Face Detection**   | OpenCV Haar cascades â†’ draw bounding boxes â†’ store snapshots + timestamps                |
| **Notifications**    | Telegram Bot API â†’ real-time alerts â†’ supports single/multiple admin users               |
| **Remote Control**   | `/start`, `/status`, `/snapshot`, `/video`, `/settings` (via Telegram chat)              |
| **Local Storage**    | SQLite database â†’ logs faces + motion timestamps â†’ quick search/retrieval                |
| **Cloud Backup**     | (Optional) Google Drive API â†’ upload captured images â†’ secure off-site storage           |
| **Extensibility**    | Modular codebase â†’ easily add new detection algorithms (e.g., deep learning models)      |

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   â”‚       â”‚                                   â”‚       â”‚                        â”‚
â”‚  ESP32-CAM /      â”‚â”€â”€â”€â–¶   â”‚      Flask Backend (app.py)       â”‚â”€â”€â”€â–¶   â”‚  Telegram Bot API      â”‚
â”‚  USB Webcam       â”‚       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚       â”‚  (bot.py)              â”‚
â”‚  (video feed)     â”‚       â”‚  â”‚  Detector Module (detector.py) â”‚ â”‚       â”‚                        â”‚
â”‚                   â”‚       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚       â”‚                        â”‚
â”‚                   â”‚       â”‚          â”‚                         â”‚       â”‚                        â”‚
â”‚                   â”‚       â”‚          â–¼                         â”‚       â”‚                        â”‚
â”‚                   â”‚       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚       â”‚                        â”‚
â”‚                   â”‚       â”‚  â”‚   Storage Module (storage.py) â”‚ â”‚       â”‚                        â”‚
â”‚                   â”‚       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚       â”‚                        â”‚
â”‚                   â”‚       â”‚          â”‚                         â”‚       â”‚                        â”‚
â”‚                   â”‚       â”‚          â–¼                         â”‚       â”‚                        â”‚
â”‚                   â”‚       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚       â”‚                        â”‚
â”‚                   â”‚       â”‚  â”‚    SQLite Database (local)    â”‚ â”‚       â”‚                        â”‚
â”‚                   â”‚       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚       â”‚                        â”‚
â”‚                   â”‚       â”‚          â”‚                         â”‚       â”‚                        â”‚
â”‚                   â”‚       â”‚          â–¼                         â”‚       â”‚                        â”‚
â”‚                   â”‚       â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚       â”‚                        â”‚
â”‚                   â”‚       â”‚  â”‚ Google Drive API (optional)    â”‚ â”‚       â”‚                        â”‚
â”‚                   â”‚       â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚       â”‚                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

1. **Camera Module (`camera.py`)**
   Handles live capture (ESP32-CAM or USB), frame buffering, and optional overlays (timestamp, motion boxes, etc.).

2. **Detector Module (`detector.py`)**

   * **Motion Detection**: Background subtraction (MOG2), contour analysis â†’ returns bounding rectangles.
   * **Face Detection**: Haar cascade classifiers â†’ stores detected faces + their timestamps.

3. **Storage Module (`storage.py`)**

   * **SQLite DB**: Tables for motion events + face snapshots (path, timestamp, metadata).
   * **Cloud Backup (Optional)**: Google Drive uploader â†’ automatically pushes new images.

4. **Flask API (`app.py`)**

   * **Endpoints**:

     * `/stream` â†’ MJPEG live stream
     * `/snapshot` â†’ Single JPEG capture
     * `/toggle_motion` â†’ Enable/disable motion detection
     * Additional RESTful endpoints (config, stats, etc.)

5. **Telegram Bot (`bot.py`)**

   * **Commands**: `/start`, `/status`, `/snapshot`, `/video`, `/settings`, `/help`
   * **Alerts**: Pushes motion/face snapshots to authorized users.
   * **Security**: Validates user IDs against a whitelist (stored in environment variables).

---

## ğŸš€ Getting Started

### Prerequisites

* **Hardware**:

  * ESP32-CAM (optional) or standard USB webcam
  * Raspberry Pi / Linux / Windows / macOS
* **Software**:

  * Python 3.8 or higher
  * (Optional) Google Drive API credentials for cloud backup

### Installation

1. **Clone the Repository**

   ```bash
   git clone https://github.com/ridjan-xhika/V.I.S.A.G.E
   cd V.I.S.A.G.E
   ```

2. **Create & Activate Virtual Environment**

   ```bash
   python3 -m venv .venv
   source .venv/bin/activate   # Linux/macOS
   .venv\Scripts\activate      # Windows
   ```

3. **Install Python Dependencies**

   ```bash
   pip install -r requirements.txt
   ```

4. **Configure Environment Variables**
   Create a `.env` file in the project root with:

   ```
   # Telegram Bot
   BOT_TOKEN=your_telegram_bot_token
   ADMIN_CHAT_ID=123456789

   # Flask API
   FLASK_APP=backend/app.py
   FLASK_ENV=production
   VISAGE_API_URL=http://localhost:5000

   # (Optional) Google Drive
   GDRIVE_CREDENTIALS_JSON=/path/to/credentials.json
   GDRIVE_FOLDER_ID=your_folder_id
   ```

5. **Initialize Database**

   ```bash
   cd backend
   python storage.py --init-db
   cd ..
   ```

6. **Start the Flask API**

   ```bash
   cd backend
   flask run --host=0.0.0.0 --port=5000
   cd ..
   ```

7. **Launch the Telegram Bot** (in a separate terminal)

   ```bash
   cd backend
   python bot.py
   ```

> **Tip:** If you need the ESP32-CAM to stream into Flask, follow [this ESP32-CAM guide](https://randomlink.example.com/esp32-cam-streaming) to configure its MJPEG endpoint and update `app.py` accordingly.

---

## ğŸ“± Usage

Once both Flask and the Telegram Bot are running:

1. **Access Live Stream**
   Open a browser and navigate to:

   ```
   http://<your_server_ip>:5000/stream
   ```

   (Replace `<your_server_ip>` with `localhost` or your machineâ€™s IP.)

2. **Interact via Telegram**

   * Search for your bot (by its name) in Telegram.
   * Send `/start` to see available commands.
   * Example:

     * `/status` â†’ Returns system uptime, motion status, face counts.
     * `/snapshot` â†’ Bot replies with the latest camera snapshot.
     * `/video` â†’ Bot records a 5-second clip and sends it.
     * `/settings` â†’ Bot shows a custom keyboard to toggle motion sensitivity, threshold, etc.

3. **View Alerts & Logs**

   * Each motion or face detection triggers a push notification (with image) to your Telegram.
   * All events are logged in `backend/visage.db` (SQLite). Use `sqlite3 visage.db` to inspect.

---


## ğŸ› ï¸ Configuration Options

| Option                  | Description                                       | Default     |
| ----------------------- | ------------------------------------------------- | ----------- |
| `VIDEO_WIDTH`           | Camera capture width (px)                         | `320`       |
| `VIDEO_HEIGHT`          | Camera capture height (px)                        | `240`       |
| `TARGET_FPS`            | Desired frame rate for streaming/detection        | `60`        |
| `MOTION_THRESHOLD`      | Minimum area (in pxÂ²) for motion to trigger alert | `500`       |
| `MOTION_SENSITIVITY`    | Background subtractor learning rate (1â€“100)       | `25`        |
| `MOTION_CHECK_INTERVAL` | Skip Nâ€“1 frames between motion checks             | `2`         |
| `DB_PATH`               | Path to SQLite database file                      | `visage.db` |
| `GDRIVE_BACKUP_ENABLED` | `true`/`false` to enable automatic Google Drive   | `false`     |

These can be set in `.env`, or adjusted in each moduleâ€™s constructor. See comments in `app.py` and `camera.py` for details.

---

## ğŸ“ˆ Monitoring & Statistics

From the Flask API, you can fetch runtime stats:

* **Endpoint:**

  ```
  GET /api/stats
  ```
* **Response Example:**

  ```json
  {
    "frame_count": 12500,
    "error_count": 0,
    "actual_fps": 58.3,
    "target_fps": 60,
    "is_running": true,
    "camera_open": true,
    "motion_detection_enabled": true,
    "motion_detected": false,
    "motion_areas_count": 0,
    "last_motion_time": 0,
    "uptime": 3600.5,
    "width": 320,
    "height": 240
  }
  ```

You can build dashboards or integrate Prometheus/Grafana if needed.

---

## ğŸ§‘â€ğŸ¤â€ğŸ§‘ Contributing

We welcome any enhancements, bug fixes, or new features! Please follow these guidelines:

1. **Fork the repository**
2. **Create a feature branch**

   ```bash
   git checkout -b feature/your-feature-name
   ```
3. **Install dependencies** (inside a virtual environment)

   ```bash
   pip install -r requirements.txt
   ```
4. **Make your changes**, include tests or examples if applicable.
5. **Run existing tests** (if you add tests, place them under `backend/tests/`)
6. **Commit & push**

   ```bash
   git add .
   git commit -m "Describe your change"
   git push origin feature/your-feature-name
   ```
7. **Open a Pull Request** with a clear description of what youâ€™ve added/changed.

> **Code Style:**
>
> * Follow PEP 8 for Python.
> * Use descriptive variable/function names and docstrings.
> * Keep each module focused (SRP â€“ Single Responsibility Principle).

---

## ğŸ“œ License

This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.

---

ğŸ‘¤ **Author**
Ridjan Xhika â€“ [ridjan.xhika@epitech.eu](mailto:ridjan.xhika@epitech.eu)

*Project â€œV.I.S.A.G.Eâ€ Â© 2025 Ridjan Xhika. All rights reserved.*
